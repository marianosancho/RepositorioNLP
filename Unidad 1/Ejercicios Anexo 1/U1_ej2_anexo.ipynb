{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enunciado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo:** \n",
    "\n",
    "Desarrollar un programa en Python que permita al usuario buscar expresiones en lunfardo, basándose en descripciones de conceptos o acciones. El sistema deberá comparar la descripción del usuario con las definiciones de un diccionario de lunfardo y devolver las tres palabras cuyas definiciones sean más parecidas a la descripción ingresada.\n",
    "\n",
    "**Preparación de Datos:**\n",
    "\n",
    "Extraiga el texto de un diccionario de lunfardo desde un recurso en línea (enlace proporcionado), y organícelo en una tabla de dos columnas:\n",
    "     - Columna 1: Palabra en lunfardo.\n",
    "     - Columna 2: Definición de la palabra.\n",
    "\n",
    "**Desarrollo del Programa:**\n",
    "\n",
    "Implemente una función `buscar_en_lunfardo(descripcion)` que realice de  las siguientes tareas las que crea útiles:\n",
    "\n",
    "  1) *Normalización:* Convertir la descripción a minúsculas y eliminar caracteres no alfanuméricos.\n",
    "\n",
    "  2) *Eliminación de stopwords:* Remover palabras que no aporten significado relevante, utilizando una lista predefinida de stopwords en español.\n",
    "\n",
    "  3) *Lematización:* Reducir las palabras a su forma base o lema, para facilitar la comparación con las definiciones del diccionario.\n",
    "\n",
    "  4) *Tokenización:* Dividir la descripción en palabras individuales para su análisis.\n",
    "\n",
    "  5) *Comparación y Conteo:* Utilizar técnicas básicas de comparación de texto para \n",
    "  identificar las tres definiciones en el diccionario que más se asemejen a la descripción ingresada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la lista de stopwords en español\n",
    "stopwords_es = [\n",
    "    'de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', \n",
    "    'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', \n",
    "    'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', \n",
    "    'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', \n",
    "    'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', \n",
    "    'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', \n",
    "    'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', \n",
    "    'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', \n",
    "    'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', \n",
    "    'vosotros', 'vosotras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', \n",
    "    'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', \n",
    "    'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'es'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del modelo de nlp\n",
    "nlp = es_core_news_sm.load()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_texto(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Función que a partir de un texto ingresado por argumento, se lo normaliza, elimina stopwords y lematiza. \n",
    "    La salida será una lista con sus palabras claves.\n",
    "    \"\"\"\n",
    "\n",
    "    # Eliminación de mayúsculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Eliminación puntuación \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Lematización del texto     \n",
    "    #nlp = es_core_news_sm.load()    \n",
    "    doc = nlp(text)\n",
    "    lemmas = [tok.lemma_.lower() for tok in doc]\n",
    "    \n",
    "    # Filtramos las palabras para eliminar las stopwords\n",
    "    palabras_filtradas = [palabra for palabra in lemmas if palabra not in stopwords_es]\n",
    "    \n",
    "    return palabras_filtradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Celda donde se carga el pdf Lunfardo y se extrae su contenido, siendo la\n",
    "palabra del lunfardo la clave del diccionario y su definición el valor de la misma.\n",
    "\"\"\" \n",
    "\n",
    "# Abre el archivo en modo binario de lectura ('rb')\n",
    "with open('Lunfardo.pdf', 'rb') as archivo:\n",
    "    # Crea un objeto PdfFileReader\n",
    "    lector = PyPDF2.PdfReader(archivo)\n",
    "\n",
    "# Inicializa una cadena vacía para almacenar el texto\n",
    "    texto = ''\n",
    "\n",
    "    # Itera sobre todas las páginas del PDF\n",
    "    for i in range(1,61):\n",
    "        # Obtiene la página\n",
    "        pagina = lector.pages[i]\n",
    "\n",
    "        # Extrae el texto de la página y lo añade a la cadena de texto\n",
    "        texto += pagina.extract_text ()\n",
    "\n",
    "# Diccionario para almacenar las palabras y definiciones\n",
    "dict_lunfardo = {}\n",
    "\n",
    "regex = r\"(\\w+(?:\\(se\\))?)\\s*:\\s*(.*?)(?=\\n\\w+|$)\"\n",
    "resultado = re.findall(regex, texto, re.DOTALL)\n",
    "dict_lunfardo = {clave: valor.strip() for clave, valor in resultado}\n",
    "\n",
    "# Limpio y lematizo las definiciones del diccionario\n",
    "for lunfardo in dict_lunfardo: \n",
    "    dict_lunfardo[lunfardo] = procesar_texto(dict_lunfardo[lunfardo])\n",
    "    try:\n",
    "        dict_lunfardo[lunfardo].remove(' ')\n",
    "    except: \n",
    "        continue\n",
    "\n",
    "\n",
    "print(dict_lunfardo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscador(dict_lunfardo : dict, text: str) -> None:\n",
    "    \"\"\" \n",
    "    Funcíon que muestra en pantalla los tres lunfardos que más se asemejan a la definición ingresada por el usuario.\n",
    "    \"\"\"\n",
    "    # Lematizo la definición ingresada\n",
    "    texto_lemma = procesar_texto(text)\n",
    "\n",
    "    # Creo un nuevo diccionario, donde la clave será el lunfardo, y su valor el porcentaje de semejanza con la definición.\n",
    "    porcentajes = {}\n",
    "\n",
    "    # Itero sobre el diccionario de lunfardos, buscando el que más se adecue a la definición.\n",
    "    for lunfardo in dict_lunfardo:\n",
    "        cont_semejanza = 0        \n",
    "        for palabra in texto_lemma: \n",
    "            if palabra in dict_lunfardo[lunfardo]:\n",
    "                cont_semejanza += 1 \n",
    "        \n",
    "        porcentajes[lunfardo] = cont_semejanza\n",
    "  \n",
    "    # Ordeno de forma descendiente el diccionario\n",
    "    porcentajes_ordenado = dict(sorted(porcentajes.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    # Muestro en pantalla los 3 lunfardos con mayor semejanza\n",
    "    tres_primeros = dict(list(porcentajes_ordenado.items())[:3])\n",
    "\n",
    "    print(tres_primeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo cliente\n",
    "buscador(dict_lunfardo, 'Persona que es tonta, con pocas capacidades mentales')\n",
    "dict_lunfardo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
